{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "if [ ! -d \".git\" ]; then \n",
    "    rm -rf * .*; #Get rid of Colab's default junk files\n",
    "    git clone -b master https://github.com/RyannDaGreat/Diffusion-Illusions .\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --upgrade -r requirements.txt\n",
    "%pip install rp --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SET YOUR PROMPTS HERE\n",
    "\n",
    "prompt_a = \"a beautiful scenery with mountains\"\n",
    "prompt_b = \"\"\n",
    "\n",
    "NUMBER_OF_SQUARES = 16 # A 4x4 twisting squares illusion\n",
    "\n",
    "#Optional: Specify what you DON'T want to see\n",
    "negative_prompt = 'blurry ugly'\n",
    "\n",
    "print()\n",
    "print('Negative prompt:',repr(negative_prompt))\n",
    "print()\n",
    "print('Chosen prompts:')\n",
    "print('    prompt_a =', repr(prompt_a)) #This will be right-side up\n",
    "print('    prompt_b =', repr(prompt_b)) #This will be upside-down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rp import *\n",
    "import numpy as np\n",
    "import rp\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import source.stable_diffusion as sd\n",
    "from easydict import EasyDict\n",
    "from source.learnable_textures import LearnableImageFourier\n",
    "from source.stable_diffusion_labels import NegativeLabel, NegativeLabel_img\n",
    "from itertools import chain\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import os\n",
    "\n",
    "result = subprocess.run('bash -c \"source /etc/network_turbo && env | grep proxy\"', shell=True, capture_output=True, text=True)\n",
    "output = result.stdout\n",
    "for line in output.splitlines():\n",
    "    if '=' in line:\n",
    "        var, value = line.split('=', 1)\n",
    "        os.environ[var] = value\n",
    "if 's' not in dir():\n",
    "    #You can select the original Stable Diffusion 1.5 or some dreambooth of it\n",
    "    model_name=\"CompVis/stable-diffusion-v1-4\"\n",
    "    model_name=\"runwayml/stable-diffusion-v1-5\"\n",
    "    # model_name=\"nitrosocke/Arcane-Diffusion\"\n",
    "    gpu=rp.select_torch_device()\n",
    "    s=sd.StableDiffusion(gpu,model_name)\n",
    "device=s.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_a = NegativeLabel(prompt_a,negative_prompt)\n",
    "label_b = NegativeLabel(prompt_b,negative_prompt)\n",
    "\n",
    "\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "image_a = Image.open('mountains.jpg')\n",
    "image_b = Image.open('jige.jpg')\n",
    "\n",
    "\n",
    "transform = transforms.ToTensor()\n",
    "image_a = transform(image_a)\n",
    "image_b = transform(image_b)\n",
    "print(image_a.shape, image_b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Image Parametrization and Initialization (this section takes vram)\n",
    "\n",
    "#Select Learnable Image Size (this has big VRAM implications!):\n",
    "#Note: We use implicit neural representations for better image quality\n",
    "#They're previously used in our paper \"TRITON: Neural Neural Textures make Sim2Real Consistent\" (see tritonpaper.github.io)\n",
    "# ... and that representation is based on Fourier Feature Networks (see bmild.github.io/fourfeat)\n",
    "\n",
    "learnable_image_maker = lambda: LearnableImageFourier(height=256,width=256,num_features=256,hidden_dim=256,scale=10).to(s.device);SIZE=256\n",
    "\n",
    "image=learnable_image_maker()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learnable_image=lambda: image()\n",
    "optim=torch.optim.SGD(image.parameters(),lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=[label_a,label_b]\n",
    "#一个learnable_image\n",
    "cond_images = [image_a, image_b]\n",
    "\n",
    "#The weight coefficients for each prompt. For example, if we have [0,1], then only the upside-down mode will be optimized\n",
    "weights=[1,1]\n",
    "\n",
    "weights=rp.as_numpy_array(weights)\n",
    "weights=weights/weights.sum()\n",
    "weights=weights*len(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For saving a timelapse\n",
    "ims=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_display_image():\n",
    "    return rp.tiled_images(\n",
    "        [\n",
    "            rp.as_numpy_image(learnable_image()),\n",
    "           \n",
    "        ],\n",
    "        length=1,\n",
    "        border_thickness=0,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_ITER=5000\n",
    "\n",
    "#Set the minimum and maximum noise timesteps for the dream loss (aka score distillation loss)\n",
    "s.max_step=MAX_STEP=990\n",
    "s.min_step=MIN_STEP=10 \n",
    "\n",
    "television = rp.JupyterDisplayChannel()\n",
    "television.display()\n",
    "\n",
    "display_eta=rp.eta(NUM_ITER, title='Status')\n",
    "\n",
    "DISPLAY_INTERVAL = 200\n",
    "\n",
    "print('Every %i iterations we display an image in the form [image_a, image_b], where'%DISPLAY_INTERVAL)\n",
    "print('    image_a = (the right-side up image)')\n",
    "print('    image_b = (image_a, but upside down)')\n",
    "print()\n",
    "print('Interrupt the kernel at any time to return the currently displayed image')\n",
    "print('You can run this cell again to resume training later on')\n",
    "print()\n",
    "print('Please expect this to take quite a while to get good images (especially on the slower Colab GPU\\'s)! The longer you wait the better they\\'ll be')\n",
    "\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "try:\n",
    "    for iter_num in range(NUM_ITER):\n",
    "        display_eta(iter_num) #Print the remaining time\n",
    "\n",
    "        preds=[]\n",
    "        weight = weights[0]\n",
    "        pred=s.train_step_multi(  #此处调用train_step\n",
    "                [label_a.embedding, label_b.embedding],\n",
    "                learnable_image()[None],\n",
    "                cond_images,\n",
    "                \n",
    "                #PRESETS (uncomment one):\n",
    "                noise_coef=.1*weight,guidance_scale=100,#10\n",
    "                # noise_coef=0,image_coef=-.01,guidance_scale=50,\n",
    "                # noise_coef=0,image_coef=-.005,guidance_scale=50,\n",
    "                # noise_coef=.1,image_coef=-.010,guidance_scale=50,\n",
    "                # noise_coef=.1,image_coef=-.005,guidance_scale=50,\n",
    "                # noise_coef=.1*weight, image_coef=-.005*weight, guidance_scale=50,\n",
    "                control_image_coef = 1*weight,\n",
    "            )\n",
    "        preds+=list(pred)\n",
    "        with torch.no_grad():\n",
    "            if iter_num and not iter_num%(DISPLAY_INTERVAL*50):\n",
    "                #Wipe the slate every 50 displays so they don't get cut off\n",
    "                from IPython.display import clear_output\n",
    "                clear_output()\n",
    "\n",
    "            if not iter_num%(DISPLAY_INTERVAL//4):\n",
    "                im = get_display_image()\n",
    "                ims.append(im)\n",
    "                television.update(im)\n",
    "                \n",
    "                if not iter_num%DISPLAY_INTERVAL:\n",
    "                    rp.display_image(im)\n",
    "\n",
    "        optim.step()\n",
    "        optim.zero_grad()\n",
    "except KeyboardInterrupt:\n",
    "    print()\n",
    "    print('Interrupted early at iteration %i'%iter_num)\n",
    "    im = get_display_image()\n",
    "    ims.append(im)\n",
    "    rp.display_image(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Unsolved Image:')\n",
    "rp.display_image(rp.as_numpy_image(learnable_image()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_run(name):\n",
    "    folder=\"untracked/parker_puzzle_runs/%s\"%name\n",
    "    if rp.path_exists(folder):\n",
    "        folder+='_%i'%time.time()\n",
    "    rp.make_directory(folder)\n",
    "    ims_names=['ims_%04i.png'%i for i in range(len(ims))]\n",
    "    with rp.SetCurrentDirectoryTemporarily(folder):\n",
    "        rp.save_images(ims,ims_names,show_progress=True)\n",
    "    print()\n",
    "    print('Saved timelapse to folder:',repr(folder))\n",
    "    \n",
    "save_run('-'.join([prompt_a,prompt_b])) #You can give it a good custom name if you want!"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
